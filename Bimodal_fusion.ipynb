{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58d057f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c895df3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.array(pd.read_csv(\"train_samples_updated.csv\"))[:, 5:]\n",
    "labels.shape\n",
    "rgb_1_train = np.load(\"final_swin_rgb_train_view1.npy\")\n",
    "rgb_0_train = np.load(\"final_swin_rgb_train_view0.npy\")\n",
    "rgb_2_train = np.load(\"final_swin_rgb_train_view2.npy\")\n",
    "print(rgb_1_train.shape, rgb_0_train.shape, rgb_2_train.shape)\n",
    "\n",
    "rgb_1_val = np.load(\"final_swin_rgb_val_view1.npy\")\n",
    "rgb_0_val = np.load(\"final_swin_rgb_val_view0.npy\")\n",
    "rgb_2_val = np.load(\"final_swin_rgb_val_view2.npy\")\n",
    "print(rgb_1_val.shape, rgb_0_val.shape, rgb_2_val.shape)\n",
    "\n",
    "dct_1_train = np.load(\"swin_mul_dct_train_view1.npy\")\n",
    "dct_0_train = np.load(\"swin_mul_dct_train_view0.npy\")\n",
    "dct_2_train = np.load(\"swin_mul_dct_train_view2.npy\")\n",
    "print(dct_1_train.shape, dct_0_train.shape, dct_2_train.shape)\n",
    "\n",
    "dct_1_val = np.load(\"swin_mul_dct_val_view1.npy\")\n",
    "dct_0_val = np.load(\"swin_mul_dct_val_view0.npy\")\n",
    "dct_2_val = np.load(\"swin_mul_dct_val_view2.npy\")\n",
    "print(dct_1_val.shape, dct_0_val.shape, dct_2_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4212a97e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_labels = np.array(pd.read_csv(\"val_samples_updated.csv\"))[:, 5:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1d0970",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer = np.load(\"train_transformer_10.npy\")\n",
    "val_transformer = np.load(\"val_transformer_10.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee377c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transformer.shape, val_transformer.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c370bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# import pandas as pd\n",
    "import glob\n",
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from math import sqrt\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.decomposition import PCA\n",
    "from keras.callbacks import ModelCheckpoint, Callback, EarlyStopping\n",
    "import scipy.io as sio\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "# import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import regularizers\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "# from tensorflow.keras.layers import merge\n",
    "# from sklearn.linear_model import LogisticRegression, LinearRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Dense, concatenate,multiply, LayerNormalization, Add\n",
    "# from sklearn.linear_model import Ridge\n",
    "from keras.layers import Lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33219f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_tensor(X):\n",
    "  s0, s1, s2 = tf.split(X, num_or_size_splits=3,axis = -1)\n",
    "  return s0,s1,s2\n",
    "\n",
    "def mul_sca(x):\n",
    "    return tf.multiply(x[0],x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7828654",
   "metadata": {},
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=5)\n",
    "# seqLen = chunk_size-1\n",
    "# seqLen = 14\n",
    "\n",
    "#Middle Input LSTM\n",
    "rgb_input_1 = Input(shape=(1024), name='input_rgb_1')\n",
    "rgb_output_1 = Dense(64, activation='relu', name='output_rgb_1')(rgb_input_1)\n",
    "\n",
    "#Middle Input LSTM\n",
    "rgb_input_2 = Input(shape=(1024), name='input_rgb_2')\n",
    "rgb_output_2 = Dense(64, activation='relu')(rgb_input_2)\n",
    "\n",
    "#Right Input LSTM\n",
    "rgb_input_3 = Input(shape=(1024), name='input_rgb_3')\n",
    "rgb_output_3 = Dense(64, activation='relu')(rgb_input_3)\n",
    "\n",
    "\n",
    "#Middle Input LSTM\n",
    "dct_input_1 = Input(shape=(1024), name='input_dct_1')\n",
    "dct_output_1 = Dense(64, activation='relu', name='output_dct_1')(dct_input_1)\n",
    "\n",
    "#Middle Input LSTM\n",
    "dct_input_2 = Input(shape=(1024), name='input_dct_2')\n",
    "dct_output_2 = Dense(64, activation='relu')(dct_input_2)\n",
    "\n",
    "#Right Input LSTM\n",
    "dct_input_3 = Input(shape=(1024), name='input_dct_3')\n",
    "dct_output_3 = Dense(64, activation='relu')(dct_input_3)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# layer = tf.keras.layers.LayerNormalization(axis=-1)\n",
    "rgb_1_nor_output = LayerNormalization()(rgb_output_1)\n",
    "rgb_2_nor_output = LayerNormalization()(rgb_output_2)\n",
    "rgb_3_nor_output = LayerNormalization()(rgb_output_3)\n",
    "\n",
    "\n",
    "dct_1_nor_output = LayerNormalization()(dct_output_1)\n",
    "dct_2_nor_output = LayerNormalization()(dct_output_2)\n",
    "dct_3_nor_output = LayerNormalization()(dct_output_3)\n",
    "\n",
    "\n",
    "#Merged Layer\n",
    "merged_rgb = concatenate([rgb_output_1, rgb_output_2, rgb_output_3], name='RGB_Concatenate')\n",
    "merge_dense_rgb = Dense(64, activation='relu')(merged_rgb)\n",
    "softmax_output_rgb = Dense(3, activation='softmax', name='soft_score_rgb')(merge_dense_rgb)\n",
    "weight_rgb1, weight_rgb2,weight_rgb3 = Lambda(split_tensor)(softmax_output_rgb)\n",
    "\n",
    "score_rgb1 = Lambda(mul_sca)([rgb_1_nor_output, weight_rgb1])\n",
    "score_rgb2 = Lambda(mul_sca)([rgb_2_nor_output, weight_rgb2])\n",
    "score_rgb3 = Lambda(mul_sca)([rgb_3_nor_output, weight_rgb3])\n",
    "additive_score_rgb = Add()([score_rgb1, score_rgb2, score_rgb3])\n",
    "\n",
    "\n",
    "\n",
    "merged_dct = concatenate([dct_output_1, dct_output_2, dct_output_3], name='DCT_Concatenate')\n",
    "merge_dense_dct = Dense(64, activation='relu')(merged_dct)\n",
    "softmax_output_dct = Dense(3, activation='softmax', name='soft_score_dct')(merge_dense_dct)\n",
    "weight_dct1, weight_dct2,weight_dct3 = Lambda(split_tensor)(softmax_output_dct)\n",
    "\n",
    "score_dct1 = Lambda(mul_sca)([dct_1_nor_output, weight_dct1])\n",
    "score_dct2 = Lambda(mul_sca)([dct_2_nor_output, weight_dct2])\n",
    "score_dct3 = Lambda(mul_sca)([dct_3_nor_output, weight_dct3])\n",
    "additive_score_dct = Add()([score_dct1, score_dct2, score_dct3])\n",
    "\n",
    "\n",
    "# transformer_features = Input(shape=(768), name='transformer')\n",
    "# trans_output= Dense(128, activation='relu', name='output_trans_1')(transformer_features)\n",
    "# tran_nor_output = LayerNormalization()(trans_output)\n",
    "\n",
    "\n",
    "\n",
    "# rgb_dct_concat = concatenate([additive_score_rgb, additive_score_dct, tran_nor_output], name='rgb_dct_Concatenate')\n",
    "rgb_dct_concat = Add()([additive_score_rgb, additive_score_dct])\n",
    "\n",
    "# final_model_output11 = Dense(256, activation='relu')(rgb_dct_concat)\n",
    "final_model_output12 = Dense(64, activation='relu')(rgb_dct_concat)\n",
    "final_model_output = Dense(14, activation='sigmoid')(final_model_output12)\n",
    "\n",
    "final_model = Model(inputs=[rgb_input_1, rgb_input_2, rgb_input_3, dct_input_1, dct_input_2, dct_input_3], outputs=final_model_output,name='Final_output')\n",
    "\n",
    "# opt = keras.optimizers.Adam(learning_rate=0.01) #Optimizer\n",
    "# final_model.compile(optimizer = opt, loss = 'binary_crossentropy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28052a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4520750a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "opt = keras.optimizers.SGD(learning_rate=0.01) #Optimizer\n",
    "final_model.compile(optimizer = opt, loss = 'binary_crossentropy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7112eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_bias_history = final_model.fit([rgb_1_train, rgb_0_train, rgb_2_train, dct_1_train, dct_0_train, dct_2_train], labels, epochs = 50, batch_size = 32, validation_split = 0.1, callbacks = [callback])\n",
    "\n",
    "# callbacks = [callback]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e52a5ead",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = final_model.predict([rgb_1_val, rgb_0_val, rgb_2_val, dct_1_val, dct_0_val, dct_2_val])\n",
    "\n",
    "predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1b4ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_csv_file = pd.read_csv(\"val_samples_updated.csv\")\n",
    "\n",
    "col_names = ['rec_no', 'subject_pos', 'start_time', 'end_time' ]\n",
    "new_train_csv = train_csv_file.drop(col_names, axis=1)\n",
    "\n",
    "#preparing train and test csv\n",
    "test_csv = new_train_csv\n",
    "# train_csv = new_train_csv[3123:]\n",
    "print(len(test_csv))\n",
    "\n",
    "Column_names = ['Settle','Legs crossed','Groom','Hand-mouth','Fold arms','Leg movement','Scratch','Gesture','Hand-face','Adjusting clothing','Fumble','Shrug','Stretching','Smearing hands']\n",
    "# Column_names = ['Hand-face','Hand-mouth','Gesture','Fumble','Scratch','Stretching','Smearing hands','Shrug','Adjusting clothing','Groom','Fold arms','Leg movement','Settle','Legs crossed']\n",
    "extracted_col = test_csv[\"sample_id\"]\n",
    "test_pred_csv = pd.DataFrame(predict, columns = Column_names)\n",
    "test_pred_csv.insert(0, \"sample_id\", extracted_col)\n",
    "# test_pred_csv.to_csv(\"test_predicted_dct_swin_fusion_\"  + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f743379",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "CLASSES = ['Hand-face','Hand-mouth','Gesture','Fumble','Scratch','Stretching','Smearing hands','Shrug','Adjusting clothing','Groom','Fold arms','Leg movement','Settle','Legs crossed']\n",
    "\n",
    "\n",
    "def evaluate(test_annotation_file,user_submission_file):\n",
    "#     test = pd.read_csv(test_annotation_file,index_col=\"sample_id\").sort_values('sample_id')\n",
    "#     user = pd.read_csv(user_submission_file,index_col=\"sample_id\").sort_values('sample_id')\n",
    "    \n",
    "    test = test_annotation_file.sort_values('sample_id')\n",
    "    \n",
    "    user = user_submission_file.sort_values('sample_id')\n",
    "    if not(np.all(test.index==user.index)):\n",
    "        raise ValueError(\"Indexes of test and prediction files do not agree.\")\n",
    "        \n",
    "    scores = []\n",
    "    for behaviour in CLASSES:\n",
    "        cur_score = average_precision_score(test[behaviour].values,user[behaviour].values)\n",
    "        scores.append(cur_score)\n",
    "    per_class_scores = pd.DataFrame({'behaviour':CLASSES,'score':scores}).set_index('behaviour')\n",
    "    macro_average = np.mean(scores)\n",
    "    return {'macro_average':macro_average,'per_class_scores':per_class_scores}\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # example usage of evaluate function\n",
    "    test_annotation_file = test_csv\n",
    "    user_submission_file = test_pred_csv # use your own predictions here\n",
    "    results = evaluate(test_annotation_file,user_submission_file)\n",
    "    print('')\n",
    "    print('--------------- MACRO AVERAGE: -----------------')\n",
    "    print('')\n",
    "    print(str(results['macro_average']))\n",
    "    print('')\n",
    "    print('--------------- PER CLASS: ---------------------')\n",
    "    print(str(results['per_class_scores']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72feebf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b557b2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f403a87",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54e7106",
   "metadata": {},
   "outputs": [],
   "source": [
    "intermediate_model_soft= Model(inputs=final_model.input ,outputs=final_model.get_layer(index = 16).output)\n",
    "# intermediate_model_soft.summary()\n",
    "rgb_weights = intermediate_model_soft.predict([rgb_1_val, rgb_0_val, rgb_2_val, dct_1_val, dct_0_val, dct_2_val])\n",
    "\n",
    "intermediate_model_soft= Model(inputs=final_model.input ,outputs=final_model.get_layer(index = 17).output)\n",
    "# intermediate_model_soft.summary()\n",
    "dct_weights = intermediate_model_soft.predict([rgb_1_val, rgb_0_val, rgb_2_val, dct_1_val, dct_0_val, dct_2_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ff4334",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(rgb_weights, axis = 0), np.mean(dct_weights, axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7c523f7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8193ea8b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f097d838",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(dct_weights).to_csv(\"RGB_Weights.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a87618dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b9147e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806445d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_model.save(\"rgb_dct_fusion_model_0.479\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca697146",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e7e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_transformer = np.load(\"test_transformer_10.npy\")\n",
    "\n",
    "rgb_1_test = np.load(\"final_swin_rgb_test_view1.npy\")\n",
    "rgb_0_test = np.load(\"final_swin_rgb_test_view0.npy\")\n",
    "rgb_2_test = np.load(\"final_swin_rgb_test_view2.npy\")\n",
    "\n",
    "dct_1_test = np.load(\"swin_mul_dct_test_view1.npy\")\n",
    "dct_0_test = np.load(\"swin_mul_dct_test_view0.npy\")\n",
    "dct_2_test = np.load(\"swin_mul_dct_test_view2.npy\")\n",
    "\n",
    "print(test_transformer.shape)\n",
    "print(rgb_1_test.shape, rgb_0_test.shape, rgb_2_test.shape, dct_1_test.shape, dct_0_test.shape, dct_2_test.shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb10cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predict = final_model.predict([rgb_1_test, rgb_0_test, rgb_2_test, dct_1_test, dct_0_test, dct_2_test])\n",
    "\n",
    "test_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0d40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fake_csv_file = pd.read_csv(\"fake_predictions_test.csv\")\n",
    "\n",
    "\n",
    "# train_csv = new_train_csv[3123:]\n",
    "print(len(test_fake_csv_file))\n",
    "\n",
    "Column_names = ['Settle','Legs crossed','Groom','Hand-mouth','Fold arms','Leg movement','Scratch','Gesture','Hand-face','Adjusting clothing','Fumble','Shrug','Stretching','Smearing hands']\n",
    "# Column_names = ['Hand-face','Hand-mouth','Gesture','Fumble','Scratch','Stretching','Smearing hands','Shrug','Adjusting clothing','Groom','Fold arms','Leg movement','Settle','Legs crossed']\n",
    "extracted_col = test_fake_csv_file[\"sample_id\"]\n",
    "test_pred_csv = pd.DataFrame(test_predict, columns = Column_names)\n",
    "test_pred_csv.insert(0, \"sample_id\", extracted_col)\n",
    "# test_pred_csv.to_csv(\"test_predicted_fusion_version_11\"  + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d9d4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(test_fake_csv_file), len(test_pred_csv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "371395de",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_pred_csv\n",
    "test_pred_csv.to_csv(\"test4\"  + \".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f98ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_fake_csv_file.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65307116",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd, numpy as np\n",
    "from sklearn.metrics import average_precision_score\n",
    "\n",
    "\n",
    "CLASSES = ['Hand-face','Hand-mouth','Gesture','Fumble','Scratch','Stretching','Smearing hands','Shrug','Adjusting clothing','Groom','Fold arms','Leg movement','Settle','Legs crossed']\n",
    "\n",
    "\n",
    "def evaluate(test_annotation_file,user_submission_file):\n",
    "#     test = pd.read_csv(test_annotation_file,index_col=\"sample_id\").sort_values('sample_id')\n",
    "#     user = pd.read_csv(user_submission_file,index_col=\"sample_id\").sort_values('sample_id')\n",
    "    \n",
    "    test = test_annotation_file.sort_values('sample_id')\n",
    "    \n",
    "    user = user_submission_file.sort_values('sample_id')\n",
    "    if not(np.all(test.index==user.index)):\n",
    "        raise ValueError(\"Indexes of test and prediction files do not agree.\")\n",
    "        \n",
    "    scores = []\n",
    "    for behaviour in CLASSES:\n",
    "        cur_score = average_precision_score(test[behaviour].values,user[behaviour].values)\n",
    "        scores.append(cur_score)\n",
    "    per_class_scores = pd.DataFrame({'behaviour':CLASSES,'score':scores}).set_index('behaviour')\n",
    "    macro_average = np.mean(scores)\n",
    "    return {'macro_average':macro_average,'per_class_scores':per_class_scores}\n",
    "\n",
    "\n",
    "\n",
    "if __name__=='__main__':\n",
    "    # example usage of evaluate function\n",
    "    test_annotation_file = test_fake_csv_file\n",
    "    user_submission_file = test_pred_csv # use your own predictions here\n",
    "    results = evaluate(test_annotation_file,user_submission_file)\n",
    "    print('')\n",
    "    print('--------------- MACRO AVERAGE: -----------------')\n",
    "    print('')\n",
    "    print(str(results['macro_average']))\n",
    "    print('')\n",
    "    print('--------------- PER CLASS: ---------------------')\n",
    "    print(str(results['per_class_scores']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c815969",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ab3a712",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ad849",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87effe5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77abf651",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324fc5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model.save(\"additive_rgb_dct_transformer_50_0.472\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe4bb36f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa0a055",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import plot_model\n",
    "plot_model(final_model, to_file='model12.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c2679f8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
